{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83f679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.utils.logging import setup_logging\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.ollama import OllamaChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.contents import ChatMessageContent, FunctionCallContent, FunctionResultContent\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "\n",
    "from semantic_kernel.connectors.mcp import MCPStreamableHttpPlugin\n",
    "\n",
    "import logging\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b85d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MCP plugin added to kernel\n",
      "ü§ñ Assistant ready! You can ask me to use any of the MCP tools listed above.\n",
      "üí° Example: 'Can you help me with fantasy football data?'\n",
      "Type 'exit' to quit.\n",
      "\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-20 09:35:25 - semantic_kernel.connectors.ai.chat_completion_client_base:284 - INFO] processing 1 tool calls in parallel.\n",
      "[2025-08-20 09:35:25 - semantic_kernel.kernel:412 - INFO] Calling ff_tools-get_teams function with args: {}\n",
      "[2025-08-20 09:35:25 - semantic_kernel.functions.kernel_function:19 - INFO] Function ff_tools-get_teams invoking.\n",
      "[2025-08-20 09:35:25 - semantic_kernel.functions.kernel_function:29 - INFO] Function ff_tools-get_teams succeeded.\n",
      "[2025-08-20 09:35:25 - semantic_kernel.functions.kernel_function:53 - INFO] Function completed. Duration: 0.021738s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "Here<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " are<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " all<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " the<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " teams<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " in<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " your<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " league<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      ":\n",
      "\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "|<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " Team<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " |<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " Short<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " name<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " |<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " Team<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " ID<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " |<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " Logo<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " |\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "|<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "------<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "|<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "------------<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "|<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "---------<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "|<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "------<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "|\n",
      "<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "|<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " America<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "‚Äôs<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " Fantasy<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " Team<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " |<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " Tom<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " |<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      " <async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "42<async_generator object ChatCompletionClientBase.get_streaming_chat_message_content at 0x000001DCBE2058A0>\n",
      "w"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-08-20 09:35:27 - opentelemetry.context:157 - ERROR] Failed to detach context\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\blaineperry\\git\\semantic_kernel_mcp_client\\.venv\\Lib\\site-packages\\opentelemetry\\trace\\__init__.py\", line 589, in use_span\n",
      "    yield span\n",
      "  File \"c:\\Users\\blaineperry\\git\\semantic_kernel_mcp_client\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\chat_completion_client_base.py\", line 271, in get_streaming_chat_message_contents\n",
      "    yield messages\n",
      "GeneratorExit\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\blaineperry\\git\\semantic_kernel_mcp_client\\.venv\\Lib\\site-packages\\opentelemetry\\context\\__init__.py\", line 155, in detach\n",
      "    _RUNTIME_CONTEXT.detach(token)\n",
      "  File \"c:\\Users\\blaineperry\\git\\semantic_kernel_mcp_client\\.venv\\Lib\\site-packages\\opentelemetry\\context\\contextvars_context.py\", line 53, in detach\n",
      "    self._current_context.reset(token)\n",
      "ValueError: <Token var=<ContextVar name='current_context' default={} at 0x000001DCBA341E90> at 0x000001DCBE254400> was created in a different Context\n"
     ]
    }
   ],
   "source": [
    "\n",
    "async def main():\n",
    "    # Initialize the kernel\n",
    "    kernel = Kernel()\n",
    "\n",
    "    # Add Azure OpenAI chat completion\n",
    "    chat_completion = OllamaChatCompletion(\n",
    "        ai_model_id=\"gpt-oss:20b\",\n",
    "        host=\"http://ollama.home\",\n",
    "    )\n",
    "    kernel.add_service(chat_completion)\n",
    "\n",
    "    # Set up logging to see detailed information\n",
    "    setup_logging()\n",
    "    \n",
    "    # Configure logging levels for different components\n",
    "    logging.getLogger(\"semantic_kernel\").setLevel(logging.INFO)\n",
    "    logging.getLogger(\"semantic_kernel.kernel\").setLevel(logging.INFO)\n",
    "    logging.getLogger(\"semantic_kernel.connectors\").setLevel(logging.INFO)\n",
    "    \n",
    "    # Set up a basic console handler if not already configured\n",
    "    if not logging.getLogger().handlers:\n",
    "        logging.basicConfig(\n",
    "            level=logging.DEBUG,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "\n",
    "    \n",
    "    ff_server =  MCPStreamableHttpPlugin(\n",
    "        name=\"ff_tools\",\n",
    "        url=\"http://192.168.86.103:8000/mcp\",\n",
    "    )\n",
    "    await ff_server.connect()  \n",
    "\n",
    "    kernel.add_plugin(ff_server)\n",
    "    print(\"‚úÖ MCP plugin added to kernel\")\n",
    "\n",
    "    # Enable planning\n",
    "    execution_settings = AzureChatPromptExecutionSettings()\n",
    "    execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "    # Create a history of the conversation\n",
    "    history = ChatHistory()\n",
    "\n",
    "    print(\"ü§ñ Assistant ready! You can ask me to use any of the MCP tools listed above.\")\n",
    "    print(\"üí° Example: 'Can you help me with fantasy football data?'\")\n",
    "    print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "    # Initiate a back-and-forth chat\n",
    "    userInput = None\n",
    "    while True:\n",
    "        # Collect user input\n",
    "        userInput = \"what teams are there\"\n",
    "\n",
    "        # Terminate the loop if the user says \"exit\"\n",
    "        if userInput == \"exit\":\n",
    "            break\n",
    "\n",
    "        # Add user input to the history\n",
    "        history.add_user_message(userInput)\n",
    "\n",
    "        # Try streaming responses if the client supports it; otherwise fall back\n",
    "        thread = None\n",
    "\n",
    "                # This callback function will be called for each intermediate message,\n",
    "        # which will allow one to handle FunctionCallContent and FunctionResultContent.\n",
    "        # If the callback is not provided, the agent will return the final response\n",
    "        # with no intermediate tool call steps.\n",
    "        async def handle_streaming_intermediate_steps(message: ChatMessageContent) -> None:\n",
    "            for item in message.items or []:\n",
    "                if isinstance(item, FunctionResultContent):\n",
    "                    print(f\"Function Result:> {item.result} for function: {item.name}\")\n",
    "                elif isinstance(item, FunctionCallContent):\n",
    "                    print(f\"Function Call:> {item.name} with arguments: {item.arguments}\")\n",
    "                else:\n",
    "                    print(f\"{item}\")\n",
    "\n",
    "        # Accumulate content so we can add a single message to history at the end\n",
    "        full_response = \"\"\n",
    "\n",
    "        # Enforce streaming-only mode: require invoke_stream on the client\n",
    "        if not hasattr(chat_completion, \"get_streaming_chat_message_contents\"):\n",
    "            raise RuntimeError(\n",
    "                \"The configured chat_completion client does not support streaming (invoke_stream).\\n\"\n",
    "                \"This script is running in streaming-only mode. Use a streaming-capable client.\"\n",
    "            )\n",
    "\n",
    "        thread = None\n",
    "        i = 0\n",
    "        chunks = []\n",
    "        try:\n",
    "            response = chat_completion.get_streaming_chat_message_content(\n",
    "                messages=userInput,\n",
    "                thread=thread,\n",
    "                on_intermediate_message=handle_streaming_intermediate_steps,\n",
    "                chat_history=history,\n",
    "                settings=execution_settings,\n",
    "                kernel=kernel,\n",
    "            )\n",
    "                \n",
    "            async for chunk in response:\n",
    "                chunks.append(chunk)\n",
    "                i+=1\n",
    "                print(chunk, end=\"\")\n",
    "\n",
    "                if i > 90:\n",
    "                    return chunks\n",
    "\n",
    "                    break\n",
    "                \n",
    "                print(response)\n",
    "                # thread = response.thread\n",
    "                # if first_chunk:\n",
    "                #     print(f\"# {response.name}: \", end=\"\", flush=True)\n",
    "                #     first_chunk = False\n",
    "                # print(response.content, end=\"\", flush=True)\n",
    "            print()\n",
    "            # Newline after stream finishes\n",
    "            print()\n",
    "\n",
    "            if full_response:\n",
    "                history.add_message(full_response)\n",
    "        finally:\n",
    "            # Clean up the thread on the remote service if provided\n",
    "            if thread:\n",
    "                try:\n",
    "                    await thread.delete()\n",
    "                except Exception:\n",
    "                    # Best-effort cleanup; ignore errors\n",
    "                    pass\n",
    "    await ff_server.close()\n",
    "\n",
    "\n",
    "test = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1762da63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.145893247Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='User', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.154899647Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' asks', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.163695488Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=':', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.172728048Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' \"', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.182841952Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='what', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.191708426Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' teams', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.200823603Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' are', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.209712933Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' there', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.218546575Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='\".', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.227296278Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' Lik', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.236196579Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='ely', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.245347923Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' wants', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.254472251Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' list', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.263416128Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' of', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.272294176Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' teams', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.281177541Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' in', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.290097712Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' the', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.29900315Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' league', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.30788344Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='.', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.31682411Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' Use', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.325494428Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' ff', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.334140108Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='_tools', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.342737307Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='_get', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.351314999Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='_', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.360041209Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='teams', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.368671666Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='.', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:26.54242284Z', done=True, done_reason='stop', total_duration=862865311, load_duration=120770428, prompt_eval_count=666, prompt_eval_duration=147152935, eval_count=49, eval_duration=594117292, message=Message(role='assistant', content='', thinking=None, images=None, tool_name=None, tool_calls=[ToolCall(function=Function(name='ff_tools-get_teams', arguments={}))])), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b', 'usage': CompletionUsage(prompt_tokens=666, prompt_tokens_details=None, completion_tokens=49, completion_tokens_details=None)}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[FunctionCallContent(inner_content=ToolCall(function=Function(name='ff_tools-get_teams', arguments={})), ai_model_id='gpt-oss:20b', metadata={}, content_type='function_call', id=None, call_id=None, index=None, name='ff_tools-get_teams', function_name='get_teams', plugin_name='ff_tools', arguments={})], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=None, ai_model_id='gpt-oss:20b', metadata={}, content_type='message', role=<AuthorRole.TOOL: 'tool'>, name=None, items=[FunctionResultContent(inner_content=FunctionResult(function=KernelFunctionMetadata(name='get_teams', plugin_name='ff_tools', description='Get a list of teams in the league', parameters=[], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='list[TextContent, ImageContent, BinaryContent]', is_required=True, type_object=<class 'list'>, schema_data={'type': 'array'}, include_in_function_choices=True), additional_properties={}), value=[TextContent(inner_content=TextContent(type='text', text='{\"America‚Äôs Fantasy Team\":{\"team_id\":\"42w0melkm5l3630v\",\"name\":\"America‚Äôs Fantasy Team\",\"short\":\"Tom\",\"logo\":\"https://fantraximg.com/logos/0k3/tmLogo_0k3h7feyme6dj7ai_256.webp\"},\"Chance (not Chase)\":{\"team_id\":\"9jmei5inm5l3630s\",\"name\":\"Chance (not Chase)\",\"short\":\"üí©\",\"logo\":\"https://fantraximg.com/logos/j59/tmLogo_j59x2e11lhakpwg5_256.jpg\"},\"Gettin\\' Breecey Wit It\":{\"team_id\":\"ufreqjuxm5l36310\",\"name\":\"Gettin\\' Breecey Wit It\",\"short\":\"8==D\",\"logo\":\"https://fantraximg.com/logos/h42/tmLogo_h42033t6jkv68hjw_256.jpg\"},\"Gridiron Gang\":{\"team_id\":\"rqvqqkiim5l3630p\",\"name\":\"Gridiron Gang\",\"short\":\"·ïï(‚åê‚ñ†_‚ñ†)·ïó\",\"logo\":\"https://fantraximg.com/logos/ohf/tmLogo_ohfrc6lwl8ikxa20_256.jpg\"},\"In GPT We Trust\":{\"team_id\":\"re531ldvm5l3630n\",\"name\":\"In GPT We Trust\",\"short\":\"Blaine\",\"logo\":\"https://fantraximg.com/logos/m6y/tmLogo_m6ybvtoimefyr5rh_256.webp\"},\"Joe Buck Yourself\":{\"team_id\":\"h6owh9fgm5l3630q\",\"name\":\"Joe Buck Yourself\",\"short\":\"BuckU\",\"logo\":\"https://fantraximg.com/logos/2ja/tmLogo_2javvmbjko7w5alr_256.jpg\"},\"Kool name still pending\":{\"team_id\":\"krwwl8yrm5l36311\",\"name\":\"Kool name still pending\",\"short\":\"üá∫üá∏\",\"logo\":\"https://fantraximg.com/logos/g18/tmLogo_g18cx52qjv5ne155_256.jpg\"},\"Mr. Rodgers Naber-hood\":{\"team_id\":\"lkvfyldsm5l36313\",\"name\":\"Mr. Rodgers Naber-hood\",\"short\":\"CB\",\"logo\":\"https://fantraximg.com/logos/nj5/tmLogo_nj5pbadplw0yyoeo_256.jpg\"},\"Off To Grandma\":{\"team_id\":\"oaksi8o0m5l3630y\",\"name\":\"Off To Grandma\",\"short\":\"OFF\",\"logo\":\"https://fantraximg.com/logos/7gw/tmLogo_7gwdpynvm0ctl087_256.jpg\"},\"Penix Pumpers\":{\"team_id\":\"ow6lk9ybm5l3630w\",\"name\":\"Penix Pumpers\",\"short\":\"PPs\",\"logo\":\"https://fantraximg.com/logos/ff3/tmLogo_ff3h3mw0kvpqj1gp_256.jpg\"},\"Redstone Red Rockets\":{\"team_id\":\"dfvhrt8dm5l3630t\",\"name\":\"Redstone Red Rockets\",\"short\":\"AF\",\"logo\":\"https://fantraximg.com/logos/s9u/tmLogo_s9u0tlesm5n38qgz_256.jpg\"},\"Yinzer Fan Club\":{\"team_id\":\"mrpx3lr7m5l3630l\",\"name\":\"Yinzer Fan Club\",\"short\":\"YINZ\",\"logo\":\"https://fantraximg.com/logos/0m0/tmLogo_0m06u8z4lh98quif_256.jpg\"}}', annotations=None, meta=None), ai_model_id=None, metadata={}, content_type='text', text='{\"America‚Äôs Fantasy Team\":{\"team_id\":\"42w0melkm5l3630v\",\"name\":\"America‚Äôs Fantasy Team\",\"short\":\"Tom\",\"logo\":\"https://fantraximg.com/logos/0k3/tmLogo_0k3h7feyme6dj7ai_256.webp\"},\"Chance (not Chase)\":{\"team_id\":\"9jmei5inm5l3630s\",\"name\":\"Chance (not Chase)\",\"short\":\"üí©\",\"logo\":\"https://fantraximg.com/logos/j59/tmLogo_j59x2e11lhakpwg5_256.jpg\"},\"Gettin\\' Breecey Wit It\":{\"team_id\":\"ufreqjuxm5l36310\",\"name\":\"Gettin\\' Breecey Wit It\",\"short\":\"8==D\",\"logo\":\"https://fantraximg.com/logos/h42/tmLogo_h42033t6jkv68hjw_256.jpg\"},\"Gridiron Gang\":{\"team_id\":\"rqvqqkiim5l3630p\",\"name\":\"Gridiron Gang\",\"short\":\"·ïï(‚åê‚ñ†_‚ñ†)·ïó\",\"logo\":\"https://fantraximg.com/logos/ohf/tmLogo_ohfrc6lwl8ikxa20_256.jpg\"},\"In GPT We Trust\":{\"team_id\":\"re531ldvm5l3630n\",\"name\":\"In GPT We Trust\",\"short\":\"Blaine\",\"logo\":\"https://fantraximg.com/logos/m6y/tmLogo_m6ybvtoimefyr5rh_256.webp\"},\"Joe Buck Yourself\":{\"team_id\":\"h6owh9fgm5l3630q\",\"name\":\"Joe Buck Yourself\",\"short\":\"BuckU\",\"logo\":\"https://fantraximg.com/logos/2ja/tmLogo_2javvmbjko7w5alr_256.jpg\"},\"Kool name still pending\":{\"team_id\":\"krwwl8yrm5l36311\",\"name\":\"Kool name still pending\",\"short\":\"üá∫üá∏\",\"logo\":\"https://fantraximg.com/logos/g18/tmLogo_g18cx52qjv5ne155_256.jpg\"},\"Mr. Rodgers Naber-hood\":{\"team_id\":\"lkvfyldsm5l36313\",\"name\":\"Mr. Rodgers Naber-hood\",\"short\":\"CB\",\"logo\":\"https://fantraximg.com/logos/nj5/tmLogo_nj5pbadplw0yyoeo_256.jpg\"},\"Off To Grandma\":{\"team_id\":\"oaksi8o0m5l3630y\",\"name\":\"Off To Grandma\",\"short\":\"OFF\",\"logo\":\"https://fantraximg.com/logos/7gw/tmLogo_7gwdpynvm0ctl087_256.jpg\"},\"Penix Pumpers\":{\"team_id\":\"ow6lk9ybm5l3630w\",\"name\":\"Penix Pumpers\",\"short\":\"PPs\",\"logo\":\"https://fantraximg.com/logos/ff3/tmLogo_ff3h3mw0kvpqj1gp_256.jpg\"},\"Redstone Red Rockets\":{\"team_id\":\"dfvhrt8dm5l3630t\",\"name\":\"Redstone Red Rockets\",\"short\":\"AF\",\"logo\":\"https://fantraximg.com/logos/s9u/tmLogo_s9u0tlesm5n38qgz_256.jpg\"},\"Yinzer Fan Club\":{\"team_id\":\"mrpx3lr7m5l3630l\",\"name\":\"Yinzer Fan Club\",\"short\":\"YINZ\",\"logo\":\"https://fantraximg.com/logos/0m0/tmLogo_0m06u8z4lh98quif_256.jpg\"}}', encoding=None)], rendered_prompt=None, metadata={'arguments': {}, 'used_arguments': {}}), ai_model_id='gpt-oss:20b', metadata={'arguments': {}, 'used_arguments': {}}, content_type='function_result', id='unknown', call_id=None, result=[TextContent(inner_content=TextContent(type='text', text='{\"America‚Äôs Fantasy Team\":{\"team_id\":\"42w0melkm5l3630v\",\"name\":\"America‚Äôs Fantasy Team\",\"short\":\"Tom\",\"logo\":\"https://fantraximg.com/logos/0k3/tmLogo_0k3h7feyme6dj7ai_256.webp\"},\"Chance (not Chase)\":{\"team_id\":\"9jmei5inm5l3630s\",\"name\":\"Chance (not Chase)\",\"short\":\"üí©\",\"logo\":\"https://fantraximg.com/logos/j59/tmLogo_j59x2e11lhakpwg5_256.jpg\"},\"Gettin\\' Breecey Wit It\":{\"team_id\":\"ufreqjuxm5l36310\",\"name\":\"Gettin\\' Breecey Wit It\",\"short\":\"8==D\",\"logo\":\"https://fantraximg.com/logos/h42/tmLogo_h42033t6jkv68hjw_256.jpg\"},\"Gridiron Gang\":{\"team_id\":\"rqvqqkiim5l3630p\",\"name\":\"Gridiron Gang\",\"short\":\"·ïï(‚åê‚ñ†_‚ñ†)·ïó\",\"logo\":\"https://fantraximg.com/logos/ohf/tmLogo_ohfrc6lwl8ikxa20_256.jpg\"},\"In GPT We Trust\":{\"team_id\":\"re531ldvm5l3630n\",\"name\":\"In GPT We Trust\",\"short\":\"Blaine\",\"logo\":\"https://fantraximg.com/logos/m6y/tmLogo_m6ybvtoimefyr5rh_256.webp\"},\"Joe Buck Yourself\":{\"team_id\":\"h6owh9fgm5l3630q\",\"name\":\"Joe Buck Yourself\",\"short\":\"BuckU\",\"logo\":\"https://fantraximg.com/logos/2ja/tmLogo_2javvmbjko7w5alr_256.jpg\"},\"Kool name still pending\":{\"team_id\":\"krwwl8yrm5l36311\",\"name\":\"Kool name still pending\",\"short\":\"üá∫üá∏\",\"logo\":\"https://fantraximg.com/logos/g18/tmLogo_g18cx52qjv5ne155_256.jpg\"},\"Mr. Rodgers Naber-hood\":{\"team_id\":\"lkvfyldsm5l36313\",\"name\":\"Mr. Rodgers Naber-hood\",\"short\":\"CB\",\"logo\":\"https://fantraximg.com/logos/nj5/tmLogo_nj5pbadplw0yyoeo_256.jpg\"},\"Off To Grandma\":{\"team_id\":\"oaksi8o0m5l3630y\",\"name\":\"Off To Grandma\",\"short\":\"OFF\",\"logo\":\"https://fantraximg.com/logos/7gw/tmLogo_7gwdpynvm0ctl087_256.jpg\"},\"Penix Pumpers\":{\"team_id\":\"ow6lk9ybm5l3630w\",\"name\":\"Penix Pumpers\",\"short\":\"PPs\",\"logo\":\"https://fantraximg.com/logos/ff3/tmLogo_ff3h3mw0kvpqj1gp_256.jpg\"},\"Redstone Red Rockets\":{\"team_id\":\"dfvhrt8dm5l3630t\",\"name\":\"Redstone Red Rockets\",\"short\":\"AF\",\"logo\":\"https://fantraximg.com/logos/s9u/tmLogo_s9u0tlesm5n38qgz_256.jpg\"},\"Yinzer Fan Club\":{\"team_id\":\"mrpx3lr7m5l3630l\",\"name\":\"Yinzer Fan Club\",\"short\":\"YINZ\",\"logo\":\"https://fantraximg.com/logos/0m0/tmLogo_0m06u8z4lh98quif_256.jpg\"}}', annotations=None, meta=None), ai_model_id=None, metadata={}, content_type='text', text='{\"America‚Äôs Fantasy Team\":{\"team_id\":\"42w0melkm5l3630v\",\"name\":\"America‚Äôs Fantasy Team\",\"short\":\"Tom\",\"logo\":\"https://fantraximg.com/logos/0k3/tmLogo_0k3h7feyme6dj7ai_256.webp\"},\"Chance (not Chase)\":{\"team_id\":\"9jmei5inm5l3630s\",\"name\":\"Chance (not Chase)\",\"short\":\"üí©\",\"logo\":\"https://fantraximg.com/logos/j59/tmLogo_j59x2e11lhakpwg5_256.jpg\"},\"Gettin\\' Breecey Wit It\":{\"team_id\":\"ufreqjuxm5l36310\",\"name\":\"Gettin\\' Breecey Wit It\",\"short\":\"8==D\",\"logo\":\"https://fantraximg.com/logos/h42/tmLogo_h42033t6jkv68hjw_256.jpg\"},\"Gridiron Gang\":{\"team_id\":\"rqvqqkiim5l3630p\",\"name\":\"Gridiron Gang\",\"short\":\"·ïï(‚åê‚ñ†_‚ñ†)·ïó\",\"logo\":\"https://fantraximg.com/logos/ohf/tmLogo_ohfrc6lwl8ikxa20_256.jpg\"},\"In GPT We Trust\":{\"team_id\":\"re531ldvm5l3630n\",\"name\":\"In GPT We Trust\",\"short\":\"Blaine\",\"logo\":\"https://fantraximg.com/logos/m6y/tmLogo_m6ybvtoimefyr5rh_256.webp\"},\"Joe Buck Yourself\":{\"team_id\":\"h6owh9fgm5l3630q\",\"name\":\"Joe Buck Yourself\",\"short\":\"BuckU\",\"logo\":\"https://fantraximg.com/logos/2ja/tmLogo_2javvmbjko7w5alr_256.jpg\"},\"Kool name still pending\":{\"team_id\":\"krwwl8yrm5l36311\",\"name\":\"Kool name still pending\",\"short\":\"üá∫üá∏\",\"logo\":\"https://fantraximg.com/logos/g18/tmLogo_g18cx52qjv5ne155_256.jpg\"},\"Mr. Rodgers Naber-hood\":{\"team_id\":\"lkvfyldsm5l36313\",\"name\":\"Mr. Rodgers Naber-hood\",\"short\":\"CB\",\"logo\":\"https://fantraximg.com/logos/nj5/tmLogo_nj5pbadplw0yyoeo_256.jpg\"},\"Off To Grandma\":{\"team_id\":\"oaksi8o0m5l3630y\",\"name\":\"Off To Grandma\",\"short\":\"OFF\",\"logo\":\"https://fantraximg.com/logos/7gw/tmLogo_7gwdpynvm0ctl087_256.jpg\"},\"Penix Pumpers\":{\"team_id\":\"ow6lk9ybm5l3630w\",\"name\":\"Penix Pumpers\",\"short\":\"PPs\",\"logo\":\"https://fantraximg.com/logos/ff3/tmLogo_ff3h3mw0kvpqj1gp_256.jpg\"},\"Redstone Red Rockets\":{\"team_id\":\"dfvhrt8dm5l3630t\",\"name\":\"Redstone Red Rockets\",\"short\":\"AF\",\"logo\":\"https://fantraximg.com/logos/s9u/tmLogo_s9u0tlesm5n38qgz_256.jpg\"},\"Yinzer Fan Club\":{\"team_id\":\"mrpx3lr7m5l3630l\",\"name\":\"Yinzer Fan Club\",\"short\":\"YINZ\",\"logo\":\"https://fantraximg.com/logos/0m0/tmLogo_0m06u8z4lh98quif_256.jpg\"}}', encoding=None)], name='ff_tools-get_teams', function_name='get_teams', plugin_name='ff_tools', encoding=None)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=0),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:27.991325026Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='We', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.000777351Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' need', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.010297134Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' to', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.019802255Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' answer', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.029258225Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=':', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.038647167Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' \"', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.04806499Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='what', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.057694688Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' teams', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.067196072Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' are', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.076477228Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' there', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.085807993Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='\"', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.095156315Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' We', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.106160598Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' have', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.115633517Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' the', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.124901155Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' list', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.134404332Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' from', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.143756185Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' the', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.153176867Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' tool', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.162616716Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='.', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.172180675Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' Should', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.181708383Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' format', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.191391717Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking=' nicely', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.201021182Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='', thinking='.', images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.266604241Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='Here', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='Here', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='Here', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.276087055Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' are', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' are', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' are', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.28549188Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' all', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' all', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' all', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.294824905Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' the', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' the', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' the', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.304418165Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' teams', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' teams', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' teams', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.313929835Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' in', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' in', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' in', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.32346887Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' your', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' your', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' your', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.333014584Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' league', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' league', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' league', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.342386286Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=':\\n\\n', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=':\\n\\n', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=':\\n\\n', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.352204183Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='|', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.361997388Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' Team', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' Team', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' Team', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.371796509Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' |', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.381598677Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' Short', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' Short', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' Short', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.391805679Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' name', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' name', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' name', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.401757899Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' |', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.414115248Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' Team', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' Team', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' Team', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.42417692Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' ID', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' ID', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' ID', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.434055616Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' |', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.443881712Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' Logo', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' Logo', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' Logo', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.453799811Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' |\\n', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' |\\n', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' |\\n', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.4636393Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='|', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.473658991Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='------', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='------', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='------', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.483616994Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='|', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.493355927Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='------------', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='------------', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='------------', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.503325459Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='|', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.513480819Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='---------', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='---------', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='---------', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.525185706Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='|', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.53506823Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='------', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='------', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='------', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.544928521Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='|\\n', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='|\\n', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='|\\n', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.5547499Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='|', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='|', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.564633751Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' America', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' America', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' America', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.574259574Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='‚Äôs', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='‚Äôs', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='‚Äôs', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.584095186Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' Fantasy', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' Fantasy', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' Fantasy', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.593591852Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' Team', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' Team', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' Team', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.602771617Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' |', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.611963693Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' Tom', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' Tom', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' Tom', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.621226361Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' |', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' |', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.630363204Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content=' ', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content=' ', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text=' ', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.639522993Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='42', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='42', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='42', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1),\n",
       " StreamingChatMessageContent(choice_index=0, inner_content=ChatResponse(model='gpt-oss:20b', created_at='2025-08-20T14:35:28.648723558Z', done=False, done_reason=None, total_duration=None, load_duration=None, prompt_eval_count=None, prompt_eval_duration=None, eval_count=None, eval_duration=None, message=Message(role='assistant', content='w', thinking=None, images=None, tool_name=None, tool_calls=None)), ai_model_id='gpt-oss:20b', metadata={'model': 'gpt-oss:20b'}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[StreamingTextContent(inner_content=Message(role='assistant', content='w', thinking=None, images=None, tool_name=None, tool_calls=None), ai_model_id=None, metadata={}, content_type='text', text='w', encoding=None, choice_index=0)], encoding=None, finish_reason=None, status=None, function_invoke_attempt=1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03f7fb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='assistant', content='', thinking='User', images=None, tool_name=None, tool_calls=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].inner_content['message']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 0:\n",
      "User\n",
      "Message 1:\n",
      " asks\n",
      "Message 2:\n",
      ":\n",
      "Message 3:\n",
      " \"\n",
      "Message 4:\n",
      "what\n",
      "Message 5:\n",
      " teams\n",
      "Message 6:\n",
      " are\n",
      "Message 7:\n",
      " there\n",
      "Message 8:\n",
      "\".\n",
      "Message 9:\n",
      " Lik\n",
      "Message 10:\n",
      "ely\n",
      "Message 11:\n",
      " wants\n",
      "Message 12:\n",
      " list\n",
      "Message 13:\n",
      " of\n",
      "Message 14:\n",
      " teams\n",
      "Message 15:\n",
      " in\n",
      "Message 16:\n",
      " the\n",
      "Message 17:\n",
      " league\n",
      "Message 18:\n",
      ".\n",
      "Message 19:\n",
      " Use\n",
      "Message 20:\n",
      " ff\n",
      "Message 21:\n",
      "_tools\n",
      "Message 22:\n",
      "_get\n",
      "Message 23:\n",
      "_\n",
      "Message 24:\n",
      "teams\n",
      "Message 25:\n",
      ".\n",
      "Message 26:\n",
      "[ToolCall(function=Function(name='ff_tools-get_teams', arguments={}))]\n",
      "Message 27:\n",
      "\n",
      "Message 28:\n",
      "We\n",
      "Message 29:\n",
      " need\n",
      "Message 30:\n",
      " to\n",
      "Message 31:\n",
      " answer\n",
      "Message 32:\n",
      ":\n",
      "Message 33:\n",
      " \"\n",
      "Message 34:\n",
      "what\n",
      "Message 35:\n",
      " teams\n",
      "Message 36:\n",
      " are\n",
      "Message 37:\n",
      " there\n",
      "Message 38:\n",
      "\"\n",
      "Message 39:\n",
      " We\n",
      "Message 40:\n",
      " have\n",
      "Message 41:\n",
      " the\n",
      "Message 42:\n",
      " list\n",
      "Message 43:\n",
      " from\n",
      "Message 44:\n",
      " the\n",
      "Message 45:\n",
      " tool\n",
      "Message 46:\n",
      ".\n",
      "Message 47:\n",
      " Should\n",
      "Message 48:\n",
      " format\n",
      "Message 49:\n",
      " nicely\n",
      "Message 50:\n",
      ".\n",
      "Message 51:\n",
      "Here\n",
      "Message 52:\n",
      " are\n",
      "Message 53:\n",
      " all\n",
      "Message 54:\n",
      " the\n",
      "Message 55:\n",
      " teams\n",
      "Message 56:\n",
      " in\n",
      "Message 57:\n",
      " your\n",
      "Message 58:\n",
      " league\n",
      "Message 59:\n",
      ":\n",
      "\n",
      "\n",
      "Message 60:\n",
      "|\n",
      "Message 61:\n",
      " Team\n",
      "Message 62:\n",
      " |\n",
      "Message 63:\n",
      " Short\n",
      "Message 64:\n",
      " name\n",
      "Message 65:\n",
      " |\n",
      "Message 66:\n",
      " Team\n",
      "Message 67:\n",
      " ID\n",
      "Message 68:\n",
      " |\n",
      "Message 69:\n",
      " Logo\n",
      "Message 70:\n",
      " |\n",
      "\n",
      "Message 71:\n",
      "|\n",
      "Message 72:\n",
      "------\n",
      "Message 73:\n",
      "|\n",
      "Message 74:\n",
      "------------\n",
      "Message 75:\n",
      "|\n",
      "Message 76:\n",
      "---------\n",
      "Message 77:\n",
      "|\n",
      "Message 78:\n",
      "------\n",
      "Message 79:\n",
      "|\n",
      "\n",
      "Message 80:\n",
      "|\n",
      "Message 81:\n",
      " America\n",
      "Message 82:\n",
      "‚Äôs\n",
      "Message 83:\n",
      " Fantasy\n",
      "Message 84:\n",
      " Team\n",
      "Message 85:\n",
      " |\n",
      "Message 86:\n",
      " Tom\n",
      "Message 87:\n",
      " |\n",
      "Message 88:\n",
      " \n",
      "Message 89:\n",
      "42\n",
      "Message 90:\n",
      "w\n"
     ]
    }
   ],
   "source": [
    "message_num = 0\n",
    "for message in test:\n",
    "    print(f\"Message {message_num}:\")\n",
    "    if message.inner_content is not None and message.inner_content.get('message') is not None and message.inner_content['message'].thinking is not None:\n",
    "        print(message.inner_content[\"message\"].thinking)\n",
    "\n",
    "    elif message.inner_content is not None and message.inner_content.get('message') is not None and message.inner_content['message'].tool_calls is not None:\n",
    "        print(message.inner_content[\"message\"].tool_calls)\n",
    "\n",
    "    else:\n",
    "        print(message)\n",
    "    message_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9336a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
